{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DS3000A/9000A \n",
    "\n",
    "# Final Exam â€“ Part 2 (60 pts)\n",
    "\n",
    "### Student Name: xxxxxxxx\n",
    "### Student ID: xxxxxxxx\n",
    "\n",
    "## General\n",
    "This part of the exam is **Open Book** and you will answer to the programming questions below on this Jupyter Notebook. You have **2 hours (3:00 pm - 5:00 pm)** to finish the exam and upload your notebook on OWL. \n",
    "* You **are allowed** to use any document and sources on your computer and look up documents on the internet. **You need to cite any code that you use if it is NOT from the course Labs or Tutorial examples**.\n",
    "* You or **NOT allowed** to share documents, or communicate in any other way with people inside/outside of the exam room during the final. Using AI chatbots is **NOT allowed and will be counted as cheating or plagiarism**.\n",
    "* All Figures should have a x-axis and y-axis label.\n",
    "* Add as many cells as you want, whenever you need to. \n",
    "* To finish the exam in the alloted time, you will have to work efficiently. You need to submit the exam Jupyter Notebook by the **due date (Dec 12, 2023 at 5:00 pm)** on **OWL in the Assignments / Final Exam - Part 2** where you downloaded the Dataset and Jupyter Notebook. **Late submission will be scored with 0 pts, unless you have received special accommodations. To avoid technical difficulties, start your submission at latest five to ten minutes before the deadline. To be sure, you can also submit multiple versions - only the latest version will be graded. \n",
    "\n",
    "**Ensure that your code runs correctly by choosing \"Kernel -> Restart and Run All\" before submitting.**\n",
    "\n",
    "### Additional Guidance\n",
    "\n",
    "If at any point you are not sure about the answer, then *write your assumptions clearly in your exam and proceed according to those assumptions.*\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "### YOU MAY ADD ADDITIONAL IMPORTS IF YOU WISH\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this exam, we will work on the network anomaly detection dataset \"IP_Activity_Dataset_5000.csv\". It was generated from web server access logs and collected from a real-world website in Content Delivery Networks (CDNs). Each sample/row in the dataset represents a unique Internet Protocol (IP) address with 9 columns/variables. Each feature/column is a performance indicator that reflect the state or activity of each sample/IP. The IP addresses were masked due to privacy reasons.  \n",
    "\n",
    "### Variables/Features\n",
    "Feature description: \n",
    "1.\t**requests**: the number of requests sent by per IP.\n",
    "2.\t**request-interval**:  the average time interval between consecutive requests sent by per IP. Unit: milliseconds\n",
    "3.\t**request-popularity**: what percentage of the requests sent by per IP are for popular contents.\n",
    "4.\t**bytes**: the average bytes received by per IP after requesting the content.\n",
    "5.\t**delivery-time**: the average request delivery time experienced by per IP. Unit: milliseconds\n",
    "6.\t**hit-rate**: cache hit rate of per IP.\n",
    "7.\t**nodes**: the number of nodes that received requests from per IP.\n",
    "8.\t**contents**: the number of contents/files that per IP requested for.\n",
    "9.\t**label**: 0-normal, 1-abnormal (potential cache pollution attacks). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1 - Explore dataset ( X / 5 pts )\n",
    "\n",
    "- Read the dataset \"IP_Activity_Dataset_5000.csv\" as a pandas dataframe.\n",
    "- Print the number of observations in the dataset\n",
    "- Print the number of variables in the dataset (all variables regardless of whether they are a feature or label or neither)\n",
    "- Print the number of observations for each class in the 'label' variable\n",
    "- Print the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Question 2 - Regression and Evaluation (X / 20 pts)\n",
    "Your next task is to build regression models that predicts the delivery-time of IPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 Part A - Data Splitting For Regression ( X / 2 pts )\n",
    "- Use 'delivery-time' as the target variable y for your regression models, and other variables as the feature set X.\n",
    "- Split the data into equals-sized training and test sets (do not shuffle the data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 Part B - Data Standardization ( X / 2 pts )\n",
    "- Z-standarize the input features of the training and test sets.\n",
    "- All the questions below should be based on the standarized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 Part C - Basic Lasso Regression ( X / 4 pts )\n",
    "- Build a regression model with L1 regularization (Lasso) and the default alpha value. Fit it on your training set, and set the random state to 42.\n",
    "- Report the coefficients and intercept of the model.\n",
    "- Report the Root Mean Square Error (RMSE) to evaluate the testing performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 Part D - Determine the Optimal Regularization Term ( X / 12 pts )\n",
    "- Perform Lasso Regression with 5-fold cross-validation on the training set to find and **print out** the optimal regularization parameter (alpha) value. Vary the regularization parameter (alpha) between 0.01 and 100, evenly spaced in log-space, and generate 100 values. Set the random state to 42. Tip: use LassoCV function.\n",
    "- Create a plot showing the relationship between these 100 alpha values and their corresponding mean RMSE values. Sets the scale of the x-axis to a logarithmic scale. \n",
    "- Build and fit a Lasso Regression model on the training set using the optimal alpha and a random state of 42. Report the coefficients and intercept of the model. Report the Root Mean Square Error (RMSE) to evaluate the testing performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Question 3 - Classification and Evaluation (X / 35 pts)\n",
    "Your next task is to build classification models that can identify the malicious attacker IPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part A - Data Splitting For Classification ( X / 2 pts )\n",
    "- Use 'label' as the target variable y for your classification models for abnormal IP detection, and other variables as the feature set X.\n",
    "- Split the data into equals-sized training and test sets, and ensure the balanced distribution of labels when splitting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part B - Data Standardization ( X / 2 pts )\n",
    "- Z-standarize the input features of the training and test sets.\n",
    "- All the questions below should be based on the standarized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part C - Random Forest ( X / 5 pts )\n",
    "- Build a Random Forest model that consists of 5 base decision trees with the maximum depth of 5, and fit the training set. Set random state to 42.\n",
    "- Print out the accuracy, F1-score, confusion matrix, and execution time (including both training and testing time) of the model when evaluating the testing performance of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part D - Feature Selection by Random Forest ( X / 14 pts )\n",
    "- Use the Random Forest model you built in Q3-C to generate feature importance scores and select the most important features (rank the importance scores of each feature in descending order, and only select the important features from most to least important until the accumulated relative importance score reaches 90% or 0.9).\n",
    "- Use a horizontal bar chart to plot the importance scores of all features in descending order. Add appropriate x-axis and y-axis labels.\n",
    "- Print out the selected features with their importance scores, and generate the new training and test sets with the new feature set. \n",
    "- Retrain the same Random Forest model from Q3-C on the new training set, and print out the accuracy, F1-score, confusion matrix, and execution time (including both training and testing time) of the model on the new test set.\n",
    "- Plot the ROC curve for evaluating the Random Forest model on the new test set and report the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part E - Hyperparamete Tuning of Random Forest ( X / 8 pts )\n",
    "- Use 3-fold grid search to tune two hyperparameters for the Random Forest model you built in Q3-D:\n",
    "    - The number of base estimators/decision trees (find the better value among the two numbers 10 and 20).\n",
    "    - The maximum tree depth (find the better value among the two numbers 10 and 20).\n",
    "- Print out the detected better hyperparameter values and cross-validation score.\n",
    "- Build the Random Forest model with the better hyperparameter values you found, and fit the new training set from Q3-D.\n",
    "- Report the accuracy, F1-score. confusion matrix, and execution time (including both training and testing time) of the model when evaluating the testing performance of your model on the new test set from Q3-D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 Part F - Classification Model Performance Discussion ( X / 4 pts )\n",
    "- Compare the performance of the three models from Questions 3-C, 3-D, and 3-E, and discuss reasons for performance difference.\n",
    "- Compare the execution time of the three models from Questions 3-C, 3-D, and 3-E, and discuss reasons for time/efficiency difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Written answer: Explain here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Written answer: Explain here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "**You're done! As always, double-check your work by re-running the notebook from scratch.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
