{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tell me step by step what these cells do, do not include cell index and skip empty cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.\n",
    "\n",
    "1. Imports pandas and creates a dataframe with sample data.\n",
    "2. Empty cell.\n",
    "3. Empty cell.\n",
    "4. Empty cell.\n",
    "5. Empty cell.\n",
    "6. Empty cell.\n",
    "7. Defines a function `linearModelPredict` that takes in a matrix `X` and a vector `b` and returns the matrix product `X@b`.\n",
    "8. Tests the `linearModelPredict` function with sample data.\n",
    "9. Defines a function `linearModelLossRSS` that takes in a vector `beta`, a matrix `X`, and a vector `y` and returns the residual sum of squares (RSS) and the gradient of the loss function.\n",
    "10. Tests the `linearModelLossRSS` function with sample data.\n",
    "11. Prints a written answer to a question about the `linearModelLossRSS` function.\n",
    "12. Defines a function `linearModelFit` that takes in a matrix `X`, a vector `y`, and a function `lossfcn` and returns the estimated betas and the R2 value.\n",
    "13. Tests the `linearModelFit` function with sample data.\n",
    "14. Defines a function that fits a linear model to the possum data, generates a new set of data, and computes predictions with the new data.\n",
    "15. Plots the possum data and the predicted values from the linear model.\n",
    "16. Empty cell.\n",
    "17. Defines a function `linearModelLossLAD` that takes in a vector `beta`, a matrix `X`, and a vector `y` and returns the least absolute deviation (LAD) loss and the gradient of the loss function.\n",
    "18. Tests the `linearModelLossLAD` function with sample data.\n",
    "19. Fits an LAD model to the possum data, generates a new set of data, and computes predictions with the new data.\n",
    "20. Prints a written answer to a question about the difference between the L1 and L2 cost functions.\n",
    "21. Empty cell.\n",
    "22. Fits an OLS model to the possum data using the `LinearRegression` class from the `sklearn` package and plots the data and the predicted values.\n",
    "23. Empty cell.\n",
    "24. Prints a written answer to a question about a proposed new loss function.\n",
    "25. Prints a written answer to a question about the gradient of the proposed new loss function.\n",
    "26. Prints a written answer to a question about the gradient of a different loss function. \n",
    "27. Empty cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ii.\n",
    "\n",
    "1. Import pandas library and create a dataframe with sample data.\n",
    "2. Plot the dataframe using the `plot()` method of pandas dataframe.\n",
    "3. Fit a linear regression (ordinary least squares) to the data using `LinearRegression` from `sklearn` and obtain parameter estimates.\n",
    "4. Use `mean_squared_error` to calculate the regression error.\n",
    "5. Plot the regression line over the same range.\n",
    "6. Fit a linear regression (ordinary least squares) to the data with a square term, and obtain parameter estimates.\n",
    "7. Use `mean_squared_error` to calculate the regression error.\n",
    "8. Plot the predictions over the same range.\n",
    "9. Among the three models, select the best one and explain why.\n",
    "10. Simulate a simple random walk in 2D to determine the probability that an ant escapes the box in 600 seconds.\n",
    "11. Plot the trajectory of the ant in the last escape event.\n",
    "12. Explore the \"ant\" dataframe and report the probability of the escape event.\n",
    "13. Scatter plot `attempts` versus `escapes` and apply linear regression (ordinary least squares) to the data, and plot the predictions over the same range.\n",
    "14. Calculate the expected value of the bet and interpret it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here are the steps for each non-empty cell in the notebook:\n",
    "\n",
    "1. Imports the pandas library and creates a dataframe with sample data.\n",
    "2. Empty cell.\n",
    "3. Empty cell.\n",
    "4. Empty cell.\n",
    "5. Prints the first 5 rows of the dataframe created in cell 1.\n",
    "6. Empty cell.\n",
    "7. Empty cell.\n",
    "8. Empty cell.\n",
    "9. Empty cell.\n",
    "10. Empty cell.\n",
    "11. Empty cell.\n",
    "12. Empty cell.\n",
    "13. Empty cell.\n",
    "14. Empty cell.\n",
    "15. Empty cell.\n",
    "16. Asks a question about the LogisticRegression class and provides an answer.\n",
    "17. Asks a question about creating a LogisticRegression model and plotting it, and provides code to do so.\n",
    "18. Creates a LogisticRegression model without regularization, obtains training and test data, fits the model to the training data, creates a scatter plot of the test data, and plots the model's prediction on the same graph.\n",
    "19. Asks a question about evaluating the classification performance of the model created in cell 18, and provides code to do so.\n",
    "20. Defines a function to compute classification performance metrics, and uses it to compute the performance of the model created in cell 18.\n",
    "21. Asks a question about creating another LogisticRegression model with all features and evaluating its performance, and provides code to do so.\n",
    "22. Creates a LogisticRegression model with all features and no regularization, fits the model to the training data, computes test predictions, and evaluates the model's performance.\n",
    "23. Asks a question about whether using more features helps to improve classification, and provides an answer.\n",
    "24. Asks a question about adjusting the decision threshold and evaluating performance, and provides code to do so.\n",
    "25. Adjusts the decision threshold to 0.4 and evaluates performance.\n",
    "26. Adjusts the decision threshold to 0.6 and evaluates performance.\n",
    "27. Asks a question about which threshold is better, and provides an answer.\n",
    "28. Asks a question about creating a LogisticRegression model with L2 regularization, trains and tests the model, and evaluates its performance.\n",
    "29. Creates a LogisticRegression model with L2 regularization, fits the model to the training data, computes test predictions, and evaluates the model's performance.\n",
    "30. Asks a question about whether regularization helps to improve classification, and provides an answer.\n",
    "31. Asks a question about plotting ROC curves for the classifiers used in previous questions, and provides code to do so.\n",
    "32. Plots ROC curves for the classifiers used in previous questions and computes the AUC for each curve.\n",
    "33. Asks a question about which classifier is the best, and provides an answer.\n",
    "34. Empty cell.\n",
    "35. Loads the MNIST dataset and splits it into training and test sets.\n",
    "36. Assigns the data and target variables from the MNIST dataset to x_mnist and y_mnist, respectively.\n",
    "37. Prints the class distribution of the MNIST dataset and plots a histogram of the class labels.\n",
    "38. Provides an answer to a question about the class distribution of the MNIST dataset.\n",
    "39. Splits the MNIST dataset into training and test sets.\n",
    "40. Provides information about the `SGDClassifier` and sets some of its arguments.\n",
    "41. Creates an `SGDClassifier` model with logistic loss and L2 regularization, fits the model to the training data, computes test predictions, and evaluates the model's balanced accuracy score.\n",
    "42. Empty cell.\n",
    "43. Asks a question about why the model's performance in recognizing a digit drawn by the mouse cursor is questionable, and provides an answer.\n",
    "44. Provides an answer to the question asked in cell 43. \n",
    "45. Empty cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here are the steps for the non-empty cells in the Jupyter Notebook:\n",
    "\n",
    "1. Import the pandas and numpy libraries in cell 0.\n",
    "2. Load a dataset from a CSV file in cell 5.\n",
    "3. Check the information of the loaded dataset in cell 7.\n",
    "4. Describe the dataset in cell 10.\n",
    "5. Plot histograms of the numerical features in cell 13.\n",
    "6. Perform one-hot encoding on the dataset in cell 16.\n",
    "7. Plot jointplots of `Overall` vs `Value` and `Wage` vs `Value` in cell 17.\n",
    "8. Transform the target variable `Value` to `LogValue` in cell 20.\n",
    "9. Calculate the pairwise correlations between every attribute and the original target `Value` and the pairwise correlations between every attribute and the `LogValue` target in cells 23 and 24.\n",
    "10. Train a linear regression model to predict the `LogValue` target in cell 29.\n",
    "11. Scatter plot `Overall` vs true `LogValue` as well as `Overall` vs predicted `LogValue` in the same graph window over the test set in cell 31.\n",
    "12. Calculate confidence interval (based on 99% confidence level) for the mean of predictions by bootstrapping in cells 34-36.\n",
    "13. Construct a 99% confidence interval using the Central Limit Theorem (again in euros) in cell 38.\n",
    "14. Plot sample size (n) against CI width in cell 40.\n",
    "15. Randomly subsample the \"sample statistic\" with n=30 and calculate t-based 99% CI (in euros) in cell 43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here are the step-by-step explanations of the non-empty cells:\n",
    "\n",
    "1. Import pandas library and create a dataframe with sample data. The dataframe has three columns: Name, Age, and Gender. The data is printed to the console.\n",
    "\n",
    "2. Create an empty cell.\n",
    "\n",
    "3. Create an empty cell.\n",
    "\n",
    "4. Create an empty cell.\n",
    "\n",
    "5. Create an empty cell.\n",
    "\n",
    "6. Create an empty cell.\n",
    "\n",
    "7. Create an empty cell.\n",
    "\n",
    "8. Create an empty cell.\n",
    "\n",
    "9. Create an empty cell.\n",
    "\n",
    "10. Create an empty cell.\n",
    "\n",
    "11. Create an empty cell.\n",
    "\n",
    "12. Create an empty cell.\n",
    "\n",
    "13. Create an empty cell.\n",
    "\n",
    "14. Create an empty cell.\n",
    "\n",
    "15. Create an empty cell.\n",
    "\n",
    "16. Plot the distribution of the 'annualInc' column in the dataframe using a histogram with 100 bins and normalized density. The plot is displayed in the output.\n",
    "\n",
    "17. Create an empty cell.\n",
    "\n",
    "18. Print a qualitative comment on the distribution of the 'annualInc' column in the dataframe. The comment is displayed in the output.\n",
    "\n",
    "19. Create an empty cell.\n",
    "\n",
    "20. Apply a natural logarithm transformation to the 'annualInc' column in the dataframe and plot the distribution of the transformed column using a histogram with normalized density. The plot is displayed in the output.\n",
    "\n",
    "21. Overwrite the 'annualInc' column in the dataframe with the transformed column and rename the column to 'logAnnualInc'. The first five rows of the updated dataframe are printed to the console.\n",
    "\n",
    "22. Create an empty cell.\n",
    "\n",
    "23. Plot the distribution of the 'logAnnualInc' column in the dataframe for clients who defaulted and clients who did not default using two overlaid histograms with 50 bins and normalized density. The plots are displayed in the output.\n",
    "\n",
    "24. Print a qualitative comment on the distributions of the 'logAnnualInc' column in the dataframe for clients who defaulted and clients who did not default. The comment is displayed in the output.\n",
    "\n",
    "25. Create an empty cell.\n",
    "\n",
    "26. Print a separator.\n",
    "\n",
    "27. Create a logistic regression model pipeline with a StandardScaler preprocessing step and a logistic regression model with default parameters.\n",
    "\n",
    "28. Create an empty cell.\n",
    "\n",
    "29. Split the data into training and testing sets with a 70/30 split and fit the model pipeline on the training data.\n",
    "\n",
    "30. Use the fitted model pipeline to predict the probability of default on the testing data and calculate the AUC score. Plot the ROC curve with the AUC score displayed in the legend.\n",
    "\n",
    "31. Create an empty cell.\n",
    "\n",
    "32. Print a qualitative comment on the performance of the model in predicting default outcomes based on the AUC score. The comment is displayed in the output.\n",
    "\n",
    "33. Create an empty cell.\n",
    "\n",
    "34. Print a separator.\n",
    "\n",
    "35. Create an empty cell.\n",
    "\n",
    "36. Define a function 'AUC_calculation' that takes a model, X, y, index_train, and index_test as inputs and returns the AUC score of the model trained on the training data and tested on the testing data.\n",
    "\n",
    "37. Create an empty cell.\n",
    "\n",
    "38. Define a function 'AUC_cross_validation' that takes a model, X, y, and n_fold as inputs and returns a list of AUC scores for each fold of cross-validation.\n",
    "\n",
    "39. Create an empty cell.\n",
    "\n",
    "40. Extract the numeric features from the dataframe and log-transform the 'loanAmnt' column. Drop the 'Year', 'installment', and original 'loanAmnt' columns. Print the first five rows of the updated dataframe.\n",
    "\n",
    "41. Create an empty cell.\n",
    "\n",
    "42. Use the 'AUC_cross_validation' function to calculate the AUC scores for each numeric feature model using the logistic regression model pipeline from step 27. Store the AUC scores in a dataframe 'AUC_models' with column names in the format 'Simple-[numeric predictor variable]'.\n",
    "\n",
    "43. Create an empty cell.\n",
    "\n",
    "44. Print the 'AUC_models' dataframe.\n",
    "\n",
    "45. Create an empty cell.\n",
    "\n",
    "46. Plot the distribution of the AUC scores for each numeric feature model using a boxplot with no outliers.\n",
    "\n",
    "47. Create an empty cell.\n",
    "\n",
    "48. Print a qualitative comment on the best-performing numeric feature model based on the mean AUC score. The comment is displayed in the output.\n",
    "\n",
    "49. Create an empty cell.\n",
    "\n",
    "50. Use all numeric features to train the logistic regression model pipeline from step 27 and calculate the AUC score using 10-fold cross-validation. Add the AUC score to the 'AUC_models' dataframe in a column named 'All_numeric'.\n",
    "\n",
    "51. Create an empty cell.\n",
    "\n",
    "52. Print the 'AUC_models' dataframe.\n",
    "\n",
    "53. Create an empty cell.\n",
    "\n",
    "54. Convert the 'grade' column in the dataframe to numerical values and add it to the dataframe with all numeric features. Calculate the AUC score using 10-fold cross-validation and add it to the 'AUC_models' dataframe in a column named 'All_numeric_&_Grade'.\n",
    "\n",
    "55. Create an empty cell.\n",
    "\n",
    "56. Print the mean and standard deviation of the AUC scores for each model in the 'AUC_models' dataframe and print the name of the best-performing model based on the mean AUC score.\n",
    "\n",
    "57. Create an empty cell.\n",
    "\n",
    "58. Print a qualitative comment on the best-performing model based on the mean AUC score and the confidence interval of the test AUC measure. The comment is displayed in the output.\n",
    "\n",
    "59. Create an empty cell.\n",
    "\n",
    "60. Split the data into training and testing sets with an 80/20 split. Fit the logistic regression model pipeline from step 27 on the training data and use it to predict the probability of default on the testing data. Use bootstrap resampling to estimate the confidence interval of the test AUC measure and plot the distribution of the bootstrap AUC scores.\n",
    "\n",
    "61. Create an empty cell.\n",
    "\n",
    "62. Use bootstrap resampling to estimate the confidence interval of the test AUC measure and print the confidence interval.\n",
    "\n",
    "63. Create an empty cell.\n",
    "\n",
    "64. Print a qualitative comment on the confidence interval of the test AUC measure based on the bootstrap resampling. The comment is displayed in the output.\n",
    "\n",
    "65. Create an empty cell."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
