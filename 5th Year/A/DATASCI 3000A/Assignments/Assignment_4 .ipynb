{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Lhvu0GdViwG"
   },
   "source": [
    "# Assignment 4: Constructing Confidence Interval\n",
    "\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "2.  Fix any errors which result from this.\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "4.  Submit your completed notebook to OWL by the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUPKHUcmViwT"
   },
   "source": [
    "## Global Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoRkDjgKViwX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import t\n",
    "import matplotlib.pyplot as plt\n",
    "seed=106\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "076P9zOgViwb"
   },
   "source": [
    "## Question 1 - <span style=\"color:green\">[100]</span>\n",
    "You are going to work on a dataset which lists certain attributes of the soccer players participated in the soccer world cup. We want to predict the players value and quantify the uncertainty of our prediction using what we learnt in week 4. The dataset has the following attributes:\n",
    "- `Age`: Player age in years\n",
    "- `Overall`: Player overall performance score (higher better)\n",
    "- `Potential`: Player potential score (higher better)\n",
    "- `Value`: Player value *i.e*, the amount of money in euros a club should pay in order to purchase the player (higher better)\n",
    "- `Wage`: Player stipend in euros (higher better)\n",
    "- `Preferred Foot`: Player preferred foot to play\n",
    "- `International Reputation`: Player international fame (higher better)\n",
    "- `Week Foot`: Performance score of player weak foot (higher better)\n",
    "- `Skill Moves`: Player move skill score (higher better)\n",
    "- `Body Type`: Player body type\n",
    "- `Position`: Position player holds on the pitch\n",
    "- `Height`: Player height in centimeters\n",
    "- `Weight`: Player weight in kilograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPPmZeT-Viwi"
   },
   "source": [
    "### Q 1.1 - <span style=\"color:red\">[1]</span> - Load `data.csv` and show the first 5 rows. What is the target attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1675480903228,
     "user": {
      "displayName": "Alireza Fazeli",
      "userId": "13019604121988176443"
     },
     "user_tz": 300
    },
    "id": "rydQoN0bViwl",
    "outputId": "e8bcaa12-b8ae-4c24-b733-202222d87092"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"A4_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb9EYbkYd4J9"
   },
   "source": [
    "### Q 1.2 - <span style=\"color:red\">[3]</span> - Use a pandas relevant method to reveal `Dtype` of the features and indicate whether the date set has any `Null` values. Also, do you see any categorical attributes? Name them please? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1675481296468,
     "user": {
      "displayName": "Alireza Fazeli",
      "userId": "13019604121988176443"
     },
     "user_tz": 300
    },
    "id": "-A3VkWusd4x5",
    "outputId": "0d9d8704-ad5c-49d5-a299-481b6c1a5608"
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K0p2l7GkOJZ"
   },
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "No null values, and categorical values are: Preferred Foot, Body Type, and Position"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2ei527ecgpm"
   },
   "source": [
    "### Q 1.3 - <span style=\"color:red\">[3]</span> - Use a `pandas` relevant method to get a summary statistics of the data all in one tabular output and inspect it. Which features have the lowest and highest standard deviation respectively? What was the age of the youngest player in the World Cup? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1675480955712,
     "user": {
      "displayName": "Alireza Fazeli",
      "userId": "13019604121988176443"
     },
     "user_tz": 300
    },
    "id": "cTRW8jnAcf7k",
    "outputId": "64d9a40f-5cc7-4685-8472-bf6ab8c1a251"
   },
   "outputs": [],
   "source": [
    "#print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TdZHEjLdNLT"
   },
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wage has highest standard deviation: 20502.356045\n",
    "International Reputation has lowest standard deviation: 0.400888\n",
    "The age of the youngest player in the World Cup is: 15 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMojKpCFe4Wg"
   },
   "source": [
    "### Q 1.4 - <span style=\"color:red\">[4]</span> - Use a `pandas` relevant method to see the distribution of the numerical features all in one plot window. Which ones look like Gaussian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1840,
     "status": "ok",
     "timestamp": 1675481895264,
     "user": {
      "displayName": "Alireza Fazeli",
      "userId": "13019604121988176443"
     },
     "user_tz": 300
    },
    "id": "-hVLm4Nye46J",
    "outputId": "678cc323-d87a-4cfa-f248-e669235ff94b"
   },
   "outputs": [],
   "source": [
    "#df.hist(figsize=(15, 12), bins=50)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWcCZ2vpi2bT"
   },
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, Potential, Height, and Weight looks like normal distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IDD-XCpViwp"
   },
   "source": [
    "### Q 1.5 - <span style=\"color:red\">[2]</span> - Perform one hot encoding on the dataframe to prepare the categorical values for linear regression.\n",
    "\n",
    "This can be done in different ways, two common methods are [this](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [this](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n",
    "\n",
    "Note that, in one hot encoding, a categorical attribute with $n$ distinct entries gets replaced with $n-1$ columns with entries of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p_xduNiViwr",
    "outputId": "5061b15b-2016-4c8a-97a9-b11596765b4c"
   },
   "outputs": [],
   "source": [
    "#\n",
    "df_encoded = pd.get_dummies(df, columns=['Preferred Foot', 'Body Type', 'Position'])\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7OYh1g3Viww"
   },
   "source": [
    "### Q 1.6 - <span style=\"color:red\">[4]</span> - Use `seaborn.jointplot` to plot marginal histograms to investigate the relationship between `Overall` and `Value` as well as `Wage` and `Value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytGHieW7Viw0",
    "outputId": "48bb7e1e-2904-4555-f71c-6dffb39fd6e4"
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='Overall', y='Value', data=df, kind='scatter', marginal_kws=dict(bins=30, fill=False))\n",
    "plt.title('Relationship between Overall and Value')\n",
    "plt.show()\n",
    "sns.jointplot(x='Wage', y='Value', data=df, kind='scatter', marginal_kws=dict(bins=30, fill=False))\n",
    "plt.title('Relationship between Wage and Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47Eoo9KkViw4"
   },
   "source": [
    "### Q 1.7 - <span style=\"color:red\">[12]</span> - Determine which one(s) of the attributes `Overall`, `Wage`, and `Value` should be $log$ transformed and apply the transformation. Now, repeat what you did in \"Q 1.6\" but this time use the transformed version of the attribute(s) where applicable. Make sure to concatenate your original dataframe with the transformed versions of the attributes using different names to avoid overwriting the original attributes.\n",
    "\n",
    "\n",
    "Hint: For example, you can see that \"Value\" is highly skewed to the right, therefore, you need to use the transformation for it.\n",
    "\n",
    "Hint: $log$ transform is often used to normalize skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mo7gl2-xViw8",
    "outputId": "18865953-760d-4dfc-94b7-da9dd142e540"
   },
   "outputs": [],
   "source": [
    "df[['Overall', 'Wage', 'Value']].hist(figsize=(10, 8), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df['log_Wage'] = np.log1p(df['Wage'])\n",
    "df['log_Value'] = np.log1p(df['Value'])\n",
    "sns.jointplot(x='Overall', y='log_Value', data=df, kind='scatter', marginal_kws=dict(bins=30, fill=False))\n",
    "plt.title('Relationship between Overall and log(Value)')\n",
    "plt.show()\n",
    "sns.jointplot(x='log_Wage', y='log_Value', data=df, kind='scatter', marginal_kws=dict(bins=30, fill=False))\n",
    "plt.title('Relationship between log(Wage) and log(Value)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HliTsGBtVixC"
   },
   "source": [
    "### Q 1.8 - <span style=\"color:red\">[4]</span> - Use `pandas.corr()` to output\n",
    "\n",
    "a) the pairwise correlations between every attribute and the original target (*i.e.*, before transformation), and\n",
    "\n",
    "b) the pairwise correlations between every attribute and the $log$-transformed target.\n",
    "\n",
    "For each part, the output of your code should be a table with two columns, one listing the attributes excluding the target (or transformed target), and the other column being correlation values in an ascending order.\n",
    "\n",
    "Once you have the tables, use the mean of the absolute values of the correlations (per table) as a basis to judge whether it is best to use \"LogValue\" or \"Value\" as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9Gx9SpjVixE",
    "outputId": "49fb25d3-24a5-43cc-8265-9e7d15f5404c"
   },
   "outputs": [],
   "source": [
    "# part a)\n",
    "df_encoded = pd.get_dummies(df, columns=['Preferred Foot', 'Body Type', 'Position'])\n",
    "corr = df_encoded.corr()\n",
    "print(corr)\n",
    "# part b)\n",
    "df_encoded = pd.get_dummies(df, columns=['Preferred Foot', 'Body Type', 'Position'])\n",
    "df_log = np.log(df_encoded)\n",
    "corr = df_log.corr()\n",
    "print(corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "LogValue is better"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fivi2OQJVixG"
   },
   "source": [
    "### Q 1.9 - <span style=\"color:red\">[4]</span> - What were the most positively and negatively correlated features in each table in Q 1.8? How do you interpret the positive and negative correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_32K8GzVixH"
   },
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall and Value attributes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqxVzYnhVixL"
   },
   "source": [
    "### Q 1.10 - <span style=\"color:red\">[15]</span> - Let's train a model to predict the target (*i.e.*, concluded in your answer to Q 1.8):\n",
    "1. Use `mean_squared_error` to calculate Root Mean Squared Error (RMSE) as your model scorer\n",
    "2. Split the data into train and test with `test_size=0.2, random_state=seed`\n",
    "3. Pick `LinearRegression()` from sklearn as your model\n",
    "4. Report both prediction (*i.e.*, on training set) and generalization (*i.e.*, on test set) RMSE scores of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALUaJg1SVixY",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['Preferred Foot', 'Body Type', 'Position'])\n",
    "X = df_encoded.drop(columns = \"Overall\")\n",
    "y = df['Overall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"Training RMSE: {rmse_train}\")\n",
    "print(f\"Test RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiLVJDm-Vixc"
   },
   "source": [
    "### Q 1.11 - <span style=\"color:red\">[8]</span> - Scatter plot `Overall` vs true `LogValue` as well as `Overall` vs predicted `LogValue` in the same graph window over the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kup9-zZVixd",
    "outputId": "ad289c4d-a13c-4bca-b72a-42d9a538c910"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test['Overall'], y_test, color='blue', label='True LogValue', alpha=0.6)\n",
    "plt.scatter(X_test['Overall'], y_test_pred, color='red', label='Predicted LogValue', alpha=0.6, marker='x')\n",
    "plt.title('Overall vs LogValue')\n",
    "plt.xlabel('Overall')\n",
    "plt.ylabel('LogValue')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYimk6xBVixh"
   },
   "source": [
    "### Q 1.12 - <span style=\"color:red\">[15]</span> - Calculate confidence interval (based on 99% confidence level) for the mean of target by bootstrapping. For this purpose, code a bootstrap function that in each bootstrap iteration, samples from the training set to fit the linear regression model and uses the test set to make predictions - therefore your bootstrap statistic is the average of the predictions over the test set. Your function must take as input arguments: your model, Xtrain, ytrain, Xtest, and numboot=100. The function must return only one object that is the array of recorded values for the bootstrap statistic in $\\mathrm{euros}$ - and not $log(\\mathrm{euros})$. Also, the unit of the confidence interval must be $\\mathrm{euros}$ - and not $log(\\mathrm{euros})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bs8AhoNCVixj"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aKrOrfKVixo"
   },
   "source": [
    "### Q 1.13 - <span style=\"color:red\">[6]</span> - Construct a 99% confidence interval using the Central Limit Theorem (again in $\\mathrm{euros}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLcpZuqDVixq",
    "outputId": "50ceb330-e6d1-472e-c962-81d34fd7a99d"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUqKfd0cVixs"
   },
   "source": [
    "### Q 1.14 - <span style=\"color:red\">[10]</span> - We want to see the effect of sample size ($n$) on the CI calculated from CLT. Write a `for` loop which in each iteration randomly samples from your \"sample statistic\" and calculates and stores the width of the corresponding CI in an array. Obviously, you should start from a small $n$ and increase it per iteration. After the loop, plot sample size (*i.e.*, $n$) against CI width and report your observation in one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_ZtT_HYVixt",
    "outputId": "4d452bc7-2470-4e95-f80a-f68d8c3e9e53"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew7H8K4PVixv"
   },
   "source": [
    "#### *Answer*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dViR9sbGVixw"
   },
   "source": [
    "### Q 1.15 - <span style=\"color:red\">[9]</span> - Randomly subsample your \"sample statistic\" with $n=30$ and calculate $t$-based 99% CI (in $\\mathrm{euros}$). Is it a good idea to calculate CI for this data set this way? Why?\n",
    "\n",
    "Hint: It would be a good idea to run your code for this part a few times prior to answering the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GACneM5Vixx",
    "outputId": "6790bc87-6dcf-4d07-9718-a9de0a6a7580"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQNPi8YeVix0"
   },
   "source": [
    "#### *Answer*\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3420a8792bbc8a921cecec9f5e200567f9d5b83365a03086ee32a665b051d9eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
