{"cells":[{"cell_type":"markdown","metadata":{"id":"4rf_aQAZN4J1"},"source":["# Model Selection Lab\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"wt0ThpiLN4J3"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zAa0fi0FN4J4"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold, RepeatedKFold, ShuffleSplit, LeaveOneOut\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder, OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n","from sklearn.base import BaseEstimator, TransformerMixin # need these when use Classes to create custom transformers\n","import matplotlib.pyplot as plt\n","\n","# Even though we are not using seaborn we can style the plots with it\n","sns.set_style(\"darkgrid\")\n","pd.set_option('display.max_columns', 500)\n","\n","# When printing arrays, set_printoptions controls the format\n","np.set_printoptions(precision=3)\n","\n","# Create a scorer function for cross-validation\n","sc = make_scorer(mean_squared_error)\n","\n","# pick a seed\n","seed=0"]},{"cell_type":"markdown","metadata":{"id":"TEMCV0ghN4J7"},"source":["---\n","## 1. Load Dataset and Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC1Hao4BN4J9","outputId":"213933d3-0be3-4b90-e543-2fa8b9b42874"},"outputs":[],"source":["# Read in subset of footballer data (we want to predict \"overall\")\n","data = pd.read_csv('footballer_reduced.csv')\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbX0UXbTN4J-","outputId":"1d78db5e-2fdc-4ed8-ad60-efa1bf1788e6"},"outputs":[],"source":["data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtaxMfy1N4J_","outputId":"e1e44abd-5a88-4155-e32e-281f015cafc9"},"outputs":[],"source":["data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nMfSC7cN4J_","outputId":"dd910a94-1387-4df1-88c7-7e7eef81b26b"},"outputs":[],"source":["data.work_rate_att.\n","# Normally, a label with number of instances greater than 5% of the the total entries is considered statistically significant.\n","# Otherwise, we should do regrouping and come up with new labels that are all statistically significant. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wbDfKUDN4KB","outputId":"b368a58f-3c36-4b64-9ddf-fa4836f13f3f"},"outputs":[],"source":["# Turn category into numeric variables\n","# Label Encoding with sklearn LabelEncoder()\n","dataLE = data.copy()\n","label_encoder = \n","dataLE['work_rate_att']= \n","\n","print(dataLE.loc[dataLE['work_rate_att'] == 0].work_rate_att.count())\n","print(dataLE.loc[dataLE['work_rate_att'] == 1].work_rate_att.count())\n","print(dataLE.loc[dataLE['work_rate_att'] == 2].work_rate_att.count())\n","dataLE.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t2CKbyPgN4KE","outputId":"3f2e8d91-4b23-47d7-fd91-a4c7868f05ec"},"outputs":[],"source":["# Turn category into numeric variables\n","# One-Hot Encoding with sklearn OneHotEncoder()\n","dataOHE = data.copy()\n","ohe = \n","\n","#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n","X = ohe.\n","\n","#To add this back into the original dataframe \n","dfOneHot = \n","dataOHE = \n","\n","#droping the cwork_rate_att column \n","dataOHE = \n","\n","print(dataOHE[(dataOHE['work_rate_att_0'] == 1.0)].work_rate_att_0.count())\n","print(dataOHE[(dataOHE['work_rate_att_1'] == 1.0)].work_rate_att_1.count())\n","print(dataOHE[(dataOHE['work_rate_att_2'] == 1.0)].work_rate_att_2.count())\n","\n","dataOHE.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_OnFjK0ON4KF","outputId":"6b7ced25-3a92-4ce8-ec83-525824adcdbe"},"outputs":[],"source":["# Turn category into numeric variables\n","# One-Hot Encoding with Pandas get_dummies()\n","model_data = data.copy()\n","model_data =            # the dropped one is collinear to the other two\n","\n","print(model_data[(model_data['work_rate_att_Low'] == 1.0)].work_rate_att_Low.count())\n","print(model_data[(model_data['work_rate_att_Medium'] == 1.0)].work_rate_att_Medium.count())\n","model_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBlWren_N4KG","outputId":"cf15892e-810f-4637-872a-116af84c39c0"},"outputs":[],"source":["# Create histogram of target variable\n","ax = \n","model_data.\n","\n","ax.set_xlabel(\"Overall Score\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euZl_DC_N4KH"},"outputs":[],"source":["# Define our X and y\n","X = model_data.\n","y = model_data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-Om4bfsN4KH","outputId":"74e09e0d-d7d6-42b1-c568-2d4491a21fe3"},"outputs":[],"source":["# Split into train_&_validation and test sets\n","Xtrain, Xtest, ytrain, ytest = train_test_split(\n","    \n","print(Xtrain.shape, Xtest.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"htZgxb1pN4KJ","outputId":"310390ee-9193-4bcb-9b71-8d75098eae61"},"outputs":[],"source":["# Check training and test loss\n","linmodel = LinearRegression()\n","\n","trainloss = mean_squared_error(\n","print(f\"Prediction Loss: %.3f\" %  trainloss)\n","\n","testloss = mean_squared_error(ytest, linmodel.predict(Xtest))\n","print(f\"Generalization Loss: %.3f\" % testloss)"]},{"cell_type":"markdown","metadata":{"id":"i9hW6cOQN4KJ"},"source":["## 2. Cross-validation: Define Partitions\n","\n","Cross-validation gives an estimate of a model’s generalization performance.\n","\n","For more details, see [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n","\n","For working with unbalanced classes, see [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78RfmigDN4KK","outputId":"11c7da4c-6aa1-43c6-ad4c-1e1ac37a323e"},"outputs":[],"source":["# Define Kfold cross-validation without shuffling\n","x = np.arange(20)\n","print(x,'\\n')\n","\n","kf = \n","for train, test in kf.split(x):\n","    print(\"Train set: %s, Test set: %s\" % (train, test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A69eVj3NN4KM","outputId":"8456fcf1-c744-45ec-d515-c4d04e9c955b"},"outputs":[],"source":["# Define Kfold cross-validation with random shuffling\n","x=np.arange(20)\n","\n","kf = \n","for train,test in kf.split(x):\n","    print(\"Train set: %s, Test set: %s\" % (train, test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8SMnIfmN4KM","outputId":"fa34e1f2-6b78-4dfd-d898-e788a657aa2f"},"outputs":[],"source":["# Leave-one-out cross-validation.\n","# Useful for situations when dataset is too small and you cannot afford leaving out a test set, nor do a hold-out cross-validation. \n","# You will use the average of the parameters of the trained models (per fold) to get your final model.\n","# In other words, you are doing cross-validated test set evaluation.\n","x=np.arange(20)\n","\n","loo =\n","for train,test in loo.split(x):\n","    print(\"%s %s\" % (train, test))"]},{"cell_type":"markdown","metadata":{"id":"KBqMaU_QN4KN"},"source":["## 3. Run Cross-validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_j_KpTsN4KN","outputId":"1c9a2736-214e-4493-b1a6-604527db797c"},"outputs":[],"source":["# KFold cross-validated loss without shuffling\n","kf = \n","cv_scores = \n","\n","print(f'List of CV loss:', cv_scores)\n","print(f\"Average CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLriMdnON4KN","outputId":"1b06922f-09dc-4162-9b6e-10f4cf054c11"},"outputs":[],"source":["# Simpler way for doing KFold cross-validated loss without shuffling\n","nfolds=5\n","cv_scores = \n","\n","print(f'List of CV loss:', cv_scores)\n","print(f\"Average CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVyEBtVuN4KO","outputId":"2595e0e7-e9dc-44d5-c71d-f8ac4bb437c7"},"outputs":[],"source":["# KFold cross-validated loss this time with shuffling\n","kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n","cv_scores = \n","\n","print(f'List of CV loss:', cv_scores)\n","print(f\"Average CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmwZ3oY3N4KO","outputId":"d74f2248-5328-45c1-dbab-b08ca0800085"},"outputs":[],"source":["# Leave One Out cross-validated loss\n","# Use leave-one-out (LOO) when you have too little data.\n","# It is not a good choice for the \"footballer\" dataset and this cell is just for illustration.\n","kf = LeaveOneOut()\n","cv_scores = \n","\n","# print(f'List of CV loss:', cv_scores)\n","print(f\"Average CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"markdown","metadata":{"id":"3vAGAt1GN4KP"},"source":["## 4. Use Cross-validation to Find the Best Model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# first define a scorer and a cross_validation strategy\n","sc = \n","\n","kf = \n","# kf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwXu4moMN4KP","outputId":"f6a8b64e-e012-44fe-c070-201319f68781"},"outputs":[],"source":["# Model 1\n","model1 = LinearRegression()\n","model1 = model1.fit(Xtrain, ytrain)\n","\n","trainloss = mean_squared_error(ytrain, model1.predict(Xtrain))\n","print(f\"Training loss: %.3f\" % trainloss)\n","\n","cv_scores = \n","\n","print(f\"CV loss:  %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xT07WgZN4KQ","outputId":"a09bec92-c90b-473e-9048-c8f02822ebfd"},"outputs":[],"source":["# Model 2: Squared trend for age\n","# Construct a new feature - age squared\n","Xtrain2 = Xtrain\n","Xtrain2 = \n","\n","model2 = LinearRegression()\n","model2 = model2.fit(Xtrain2, ytrain)\n","\n","trainloss = mean_squared_error(ytrain, model2.predict(Xtrain2))\n","print(f\"Training loss: %.3f\" % trainloss)\n","\n","# Print CV scores and include standard deviation. Is it an unbiased estimate?\n","cv_scores = cross_val_score(model2, Xtrain2, ytrain, cv=kf, scoring=sc)\n","\n","print(f\"CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJvlK9SWN4KQ","outputId":"a0aaeb1d-7ef3-432a-9bfb-f414d5ab309e"},"outputs":[],"source":["# Model 3: All polynomial features\n","PT =  \n","Xtrain3 = \n","print('Xtrain3 dimension is', Xtrain3.shape)\n","\n","# Run the linear regression\n","model3 = LinearRegression().fit(Xtrain3,ytrain)\n","\n","trainloss = mean_squared_error(ytrain,model3.predict(Xtrain3))\n","print(f\"\\nTraining loss: %.3f\" % trainloss)\n","\n","cv_scores = cross_val_score(model3, Xtrain3, ytrain, cv=kf, scoring=sc)\n","\n","print(f\"CV loss: %.3f +/- %.3f\" % (cv_scores.mean(), cv_scores.std()))"]},{"cell_type":"markdown","metadata":{"id":"GjycA5R-N4KR"},"source":["### Which model to choose?\n","\n","Model 1.\n","\n","Why?\n","\n","Because we choose the simplest model that is within one standard deviation of the model which has the lowest cross-validated training loss."]},{"cell_type":"markdown","metadata":{"id":"Ut0UK_nDN4KR"},"source":["## 5. Pipelines\n","\n","Pipelines allow us to \"chain\" different parts of a model building process. They are very useful to apply [transformations](https://scikit-learn.org/stable/data_transforms.html) to make sure that the transformations are being applied consistently in both training and production stages.\n","\n","For illustration, we are going to use pipelines for creating quadratic and cubic features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2j4BmjLN4KR"},"outputs":[],"source":["# Define the different pipelines \n","model1 = Pipeline([\n","    ('linear_regression', LinearRegression())\n","])\n","\n","model3 = "]},{"cell_type":"markdown","metadata":{"id":"VBCIVRIAN4KS"},"source":["### Pipelines accept any transformer that you can think of, even allowing the use of [classes](https://docs.python.org/3/tutorial/classes.html) to create a fully custom transformer. Below is an example."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVTJu2crN4KS"},"outputs":[],"source":["# Model2 with custom transform \n","class Age2(BaseEstimator, TransformerMixin):  \n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X, y=None):\n","        X = X.assign(age2 = X.age**2)\n","        return X\n","\n","model2 = "]},{"cell_type":"markdown","metadata":{"id":"ABYwrQI2N4KT"},"source":["### You can also use [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WANUhaF7N4KU","outputId":"9be22807-8ea2-41c1-af87-e74b71ae189b"},"outputs":[],"source":["# Check training loss\n","print(f\"CV Loss (Model 1): %.3f +/- %.3f\" %\n","\n","      \n","print(f\"CV Loss (Model 2): %.3f +/- %.3f\" %\n","\n","\n","print(f\"CV Loss (Model 2): %.3f +/- %.3f\" %\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8bNfDuZN4KU","outputId":"b79d5a62-ea7c-497e-8f55-2891105dc58b"},"outputs":[],"source":["# Now report generalization loss (test loss) on your final model.\n","# Always use an independent test set (hold-out test set) for this.\n","model1 = model1.fit(Xtrain,ytrain)\n","print(f\"Test loss: %.3f\" % "]},{"cell_type":"markdown","metadata":{"id":"2D2T_zBwN4KU"},"source":["## 6. Learning Curves\n","\n","If a model performs well on the training data but generalizes poorly according to the cross-validation metrics, then your model is overfitting. If it performs poorly on both, then it is underfitting. This is one way to tell when a model is too simple or too complex. A way to tell is to look at the learning curves: these are plots of the model’s performance on the training set and the validation set as a function of the training set size (or the training iteration). To generate the plots, train the model several times on different sized subsets of the training set. The following code defines a function that, given some training data, plots the learning curves of a model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEp4tRYFN4KV"},"outputs":[],"source":["def plot_learning_curves(model, X, y, rs):\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rs)\n","    train_errors, val_errors = [], []\n","    for m in range(1, len(X_train) + 1):\n","        model.fit(X_train[:m], y_train[:m])\n","        y_train_predict = model.predict(X_train[:m])\n","        y_val_predict = model.predict(X_val)\n","        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n","        val_errors.append(mean_squared_error(y_val, y_val_predict))\n","\n","    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"Training Set\")\n","    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"Validation Set\")\n","    plt.legend(loc=\"upper right\", fontsize=14)   \n","    plt.xlabel(\"Dataset Size\", fontsize=14) \n","    plt.ylabel(\"RMSE\", fontsize=14)              "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Te1aOi4iN4KV","outputId":"6dfb1c87-e5f7-4597-b6da-9445e8e0f4c0"},"outputs":[],"source":["plot_learning_curves(\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"myawF6lQN4KV"},"source":["### Is your model underfitting or overfitting?\n","\n","Underfitting.\n","\n","First, let’s look at the performance on the training data: when there are just one or two instances in the training set, the model can fit them perfectly, which is why the curve starts at zero. But as new instances are added to the training set, it becomes impossible for the model to fit the training data perfectly, it could be because, for example, the data is noisy. So the error on the training data goes up until it reaches a plateau, at which point adding new instances to the training data doesn’t make the average error much better or worse. Now let’s look at the performance of the model on the validation data. When the model is trained on very few training instances, it is incapable of generalizing properly, which is why the validation error is initially quite big. Then, as the model is shown more training examples, it learns, and thus the validation error slowly goes down. However, cannot do a good job modeling the data, so the error ends up at a plateau, very close to the other curve. These learning curves are typical of a model that’s underfitting. Both curves have reached a plateau; they are close and **fairly high**.\n","\n","If your model is underfitting the training data, adding more training examples will not help. You need to use a more complex model or come up with a better set of features (*i.e.*, feature engineering)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2ApmQuqOKS7"},"outputs":[],"source":["otss = 150 # optimal training set size read from the learning curve \n","\n","# (training Set Size)-(Validation Set Size) >= otss   i.e.,  (training Set Size)-((training Set Size)/N) >= otss\n","print(f'Lower bound on the number of folds (that is k in the k-fold)\\\n","to be greater than {int(Xtrain.shape[0]/(Xtrain.shape[0]-otss))}.')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"3420a8792bbc8a921cecec9f5e200567f9d5b83365a03086ee32a665b051d9eb"}}},"nbformat":4,"nbformat_minor":0}
