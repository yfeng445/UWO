{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow These Instructions\n",
    "\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Classification with Logistic Regression  [ __ /100  marks]\n",
    "\n",
    "\n",
    "In this assignment we will use the `diabetes` dataset, which was collected and made available by “National Institute of Diabetes and Digestive and Kidney Diseases” as part of the Pima Indians Diabetes Database. \n",
    "\n",
    "We will use logistic regression to predict whether subjects have diabetes or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1 [ _ /3 marks]\n",
    "\n",
    "Read the file `diabetes.csv` into a pandas DataFrame. Display the first 5 rows of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-06T14:01:05.882342200Z",
     "start_time": "2023-10-06T14:01:05.461113600Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ****** your code here ******\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m  \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiabetes.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ****** your code here ******\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2 [ _ /6 marks]\n",
    "\n",
    "(1) How many classes are there? How many features are available to predict the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**: 2 classes, Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI,Age"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Is the dataset class-balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****** your code here ******\n",
    "print(df.Outcome.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**: No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) For this classification problem, what is the baseline accuracy and how would you interpret it? Round into 3 decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:09:04.258814900Z",
     "start_time": "2023-10-06T15:09:04.148579800Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ****** your code here ******\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m A \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mOutcome[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutcome\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcount()\n\u001B[0;32m      4\u001B[0m B \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mOutcome[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutcome\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcount()\n\u001B[0;32m      5\u001B[0m baseline_accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(A\u001B[38;5;241m/\u001B[39m(A\u001B[38;5;241m+\u001B[39mB), \u001B[38;5;241m3\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ****** your code here ******\n",
    "\n",
    "A = df.Outcome[df['Outcome']==0].count()\n",
    "B = df.Outcome[df['Outcome']==1].count()\n",
    "baseline_accuracy = round(A/(A+B), 3)\n",
    "print(\"Baseline Accuracy is:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3 [ _ /3 marks]\n",
    "\n",
    "Use `train_test_split` with `random_state=0` to split the data into training and test sets. Leave `20%` for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the features into variable \"X\"\n",
    "# ****** your code here ******\n",
    "X = df.drop('Outcome', axis='columns').values\n",
    "\n",
    "# Store the output class values into variable \"y\" \n",
    "# ****** your code here ******\n",
    "y = df.Outcome.values\n",
    "\n",
    "# Split your X and y data using train_test_split \n",
    "# ****** your code here ******\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 [ _ /3 marks]\n",
    "\n",
    "We will use sklearn's `LogisticRegression` to solve the classification problem. Before we move on, answer the following questions by reading the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(1) Does `LogisticRegression` use a penalty by default?  If yes, what penalty?\n",
    "\n",
    "**Your answer**: \n",
    "Yes, it uses L2 regularization.\n",
    "\n",
    "    \n",
    "(2) If we apply a penalty during learning, what difference do you expect to see in the resulting coefficients (parameters), relative to not applying a penalty during learning?\n",
    "\n",
    "**Your answer**: \n",
    "Applying a penalty during learning generally results in smaller magnitude coefficients compared to not applying a penalty. This occurs because the penalty discourages large coefficients by adding a cost to the loss function that increases with the magnitude of the coefficients. Specifically:\n",
    "\n",
    "L1 Penalty (Lasso Regularization): Encourages sparsity by driving some coefficients to zero, which can lead to feature selection.\n",
    "L2 Penalty (Ridge Regularization): Shrinks the coefficients towards zero, but typically doesn't result in exactly zero coefficients.\n",
    "Elastic Net: Combines L1 and L2 penalties, encouraging both sparsity and coefficient shrinkage.\n",
    "Without a penalty, the learning algorithm may fit the data too closely, potentially leading to overfitting.\n",
    "\n",
    "    \n",
    "(3) If using the default settings of `LogisticRegression`, do you need to include a column of 1s in your feature/design matrix? Briefly explain why or why not.\n",
    "\n",
    "\n",
    "**Your answer**: \n",
    "No. Because it fits an intercept term by default, which negates the need to manually add a column of 1s to the feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 [ _ /10 marks]\n",
    "\n",
    "Create a `LogisticRegression` model with `penalty=none`. Let's fisrt train and test this classifier using only \"Insulin\" as the input feature. Make a scatter plot of the points. Plot your prediction on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression model without regularization \n",
    "# ****** your code here ******\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Obtain training data and test data  \n",
    "# ****** your code here ******\n",
    "X = df.drop('Insulin', axis='columns').values\n",
    "y = df.Insulin.values\n",
    "\n",
    "# Fit to your training data using Logistic Regression \n",
    "# ****** your code here ******\n",
    "dflr= LogisticRegression(penalty='none').fit(Xtrain,ytrain)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "\n",
    "# Create a scatter plot of the test data. \n",
    "# ****** your code here ******\n",
    "sns.scatterplot(x=Xtest[:, 0], y=Xtest[:, 1], hue=ytest)\n",
    "\n",
    "\n",
    "# Also plot your prediction using sns.lineplot\n",
    "# lineplot needs 1d vector x\n",
    "\n",
    "y_pred = dflr.predict(Xtest)\n",
    "sorted_indices = np.argsort(Xtest[:, 0])\n",
    "x_sorted = Xtest[sorted_indices, 0]\n",
    "y_pred_sorted = y_pred[sorted_indices]\n",
    "sns.lineplot(x=x_sorted, y=y_pred_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3 [ _ /10 marks]\n",
    "Evaluate the classification performance using `Accuracy`, `Recall`, `Precision`, `Sensitivity` and `Specificity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****** your code here ******\n",
    "# You can either write a function or not\n",
    "\n",
    "ytest_hat = dflr.predict(Xtest)\n",
    "\n",
    "def compute_performance(yhat, y, classes):\n",
    "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
    "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
    "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
    "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
    "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    sensitivity = recall\n",
    "    specificity = tn / (fp + tn)\n",
    "    print(\"Accuracy:\", round(acc, 3), \"Recall:\", round(recall, 3), \"Precision:\", round(precision, 3),\n",
    "          \"Sensitivity:\", round(sensitivity, 3), \"Specificity:\", round(specificity, 3))\n",
    "    \n",
    "compute_performance(ytest_hat, ytest, dflr.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1 [ _ /10 marks]\n",
    "\n",
    "Create another `LogisticRegression` model with `penalty=none`. Train and test this classifier with all features and then evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression model without regularization \n",
    "# ****** your code here ******\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "X = df.drop(\"Outcome\", axis=\"columns\")\n",
    "y = df.Outcome.values\n",
    "# Fit to your training data using Logistic Regression \n",
    "# ****** your code here ******\n",
    "DFLR = LogisticRegression(penalty='none')\n",
    "dflr = DFLR.fit(X,y)\n",
    "print(f\"Intercepts:\\n {dflr.intercept_.round(3)} \\n\\nCoefficients:\\n {dflr.coef_.round(3)}\")\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Compute your test predictions, given test inputs \n",
    "# ****** your code here ******\n",
    "\n",
    "yhat = dflr.predict(X)\n",
    "yhat_probs = dflr.predict_proba(X)\n",
    "\n",
    "# Evaluate the performance\n",
    "# ****** your code here ******\n",
    "compute_performance(yhat, y, dflr.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does using more features help to improve the classification?\n",
    "\n",
    "**Your answer** : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 [ _ /10 marks]\n",
    "Let's adjust the decision threshold from 0.5 (default) to 0.4 and 0.6, and then evlaute the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using your classifer from last question, adjust the decision threshold and get the updated predictions \n",
    "# ****** your code here ******\n",
    "threshold = 0.4\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=threshold, random_state=seed)\n",
    "\n",
    "# Evaluate the performance\n",
    "# ****** your code here ******\n",
    "compute_performance(yhat, y, dflr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using your classifer from last question, adjust the decision threshold and get the updated predictions \n",
    "# ****** your code here ******\n",
    "threshold = 0.6\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=threshold, random_state=seed)\n",
    "\n",
    "\n",
    "# Evaluate the performance\n",
    "# ****** your code here ******\n",
    "compute_performance(yhat, y, dflr.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think is a better threshold? \n",
    "\n",
    "**Your answer**: \n",
    "0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3 [ _ /10 marks]\n",
    "\n",
    "Create a final `LogisticRegression` model with `penalty=l2`, `C=0.01`. Train and test this classifier with all features and then evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression model with l2 regularization \n",
    "# ****** your code here ******\n",
    "X = df.drop('Outcome', axis='columns').values\n",
    "y = df.Outcome.values\n",
    "\n",
    "# Fit to your training data using Logistic Regression \n",
    "# ****** your code here ******\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "dflr= LogisticRegression(penalty=12,C = 0.01).fit(Xtrain,ytrain)\n",
    "# Compute your test predictions, given test inputs \n",
    "# ****** your code here ******\n",
    "y_hat = dflr.predict(X)\n",
    "\n",
    "# Evaluate the performance\n",
    "# ****** your code here ******\n",
    "compute_performance(y_hat, y, dflr.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does regularization help to improve the classification?\n",
    "\n",
    "**Your answer** : Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 [ _ /15 marks]\n",
    "\n",
    "Plot ROC Curves for the classifiers you used in questions 2.2, 3.1, and 3.3. Use AUC to determine which classifier is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use roc_curve to get FPR and TPR for each of the 3 classifiers \n",
    "# ****** your code here ******\n",
    "ytest_prob = dflr.predict_proba(Xtest)\n",
    "\n",
    "# Plot all of the ROC curves \n",
    "# ****** your code here ******\n",
    "fpr, tpr, _ = roc_curve(ytest, ytest_prob[:,1], pos_label=dflr.classes_[1]) \n",
    "ax =sns.lineplot(x=fpr,y=tpr)\n",
    "ax.set_xlabel(\"FP Rate\")\n",
    "ax.set_ylabel(\"TP Rate\")\n",
    "\n",
    "# Determine AUC for each of the ROC curves \n",
    "# ****** your code here ******\n",
    "auc(fpr,tpr).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one is the best classifier?\n",
    "\n",
    "**Your answer**: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 [ _ /10 marks]\n",
    "\n",
    "Multiclass Logistic Regression\n",
    "\n",
    "In the classification lab, we trained a binary LR classifier using the _mnist_ dataset to discriminate entries which were equal to 5 from the rest. Use the same dataset to train a multiclass **Logistic Regression** using the [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)  with `l2` regularization. So, this time you will have 10 classes, *i.e.*, 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9. For training use `max_iter=2000`, `tol=1e-3`, `random_state=seed`. For some `sklearn` functions you can set argument `n_jobs=N` to run them in parallel and speed up computations. A good value for N can be the number of physical CPU cores that your machine possesses (`N=-1` would use all cores). Check the documentations of the functions to take advantage from this where possible.\n",
    "\n",
    "First load the data and plot a histogram to comment on class distribution qualitatively. For splitting the data into train and test sets, use `test_size=0.5` and `random_state=seed`. What is the balanced accuracy score of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your written answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 [ _ /10 marks]\n",
    "\n",
    "Run the cell below to see how well your model can recognize a digit drawn by the mouse cursor. Set the variable `final_model`, run the cell, draw on the pop-up canvas, and once you close the canvas you will see the model's recognition of your input.\n",
    "\n",
    "Despite the cell using your classifier, which has a high balanced accuracy score, it often makes mistakes and its performance seems questionable. Try to explain in words why is that so?\n",
    "\n",
    "Caveat: The cell below will not run on headless servers, you will need to use a local installation of python. You might have some fun until you can get it to work, but that's ok, because I want you to try your hands on technicalities and not always rely on online services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T16:43:50.124065700Z",
     "start_time": "2023-10-06T16:43:50.077065900Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dflr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m final_model\u001B[38;5;241m=\u001B[39m\u001B[43mdflr\u001B[49m \u001B[38;5;66;03m# use the name of your final model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#!pip install tk-tools\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtkinter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dflr' is not defined"
     ]
    }
   ],
   "source": [
    "final_model=dflr # use the name of your final model\n",
    "#!pip install tk-tools\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "\n",
    "temp_file_name=\"TEMP_image_TEMP.jpg\"\n",
    "app = Tk()\n",
    "app.geometry(\"300x300\")\n",
    "canvas = tk.Canvas(app, bg='white')\n",
    "canvas.pack(anchor='nw', fill='both', expand=1)\n",
    "def get_x_and_y(event):\n",
    "    global lasx, lasy\n",
    "    lasx, lasy = event.x, event.y\n",
    "\n",
    "def draw_smth(event):\n",
    "    global lasx, lasy\n",
    "    canvas.create_line((lasx, lasy, event.x, event.y), fill='red', width=4)\n",
    "    lasx, lasy = event.x, event.y\n",
    "    ps = canvas.postscript(colormode = 'color')\n",
    "    img = Image.open(io.BytesIO(ps.encode('utf-8')))\n",
    "    img.save(temp_file_name)\n",
    "\n",
    "canvas.bind(\"<Button-1>\", get_x_and_y)\n",
    "canvas.bind(\"<B1-Motion>\", draw_smth)\n",
    "\n",
    "app.mainloop()\n",
    "img = Image.open(temp_file_name)\n",
    "#resize image to 28x28 pixels\n",
    "img = img.resize((28,28))\n",
    "#convert rgb to grayscale\n",
    "img = img.convert(\"L\")\n",
    "img = np.array(img)\n",
    "img = 255.0 - img\n",
    "plt.imshow(img, cmap = mpl.cm.binary); plt.axis(\"off\")\n",
    "# reshaping to support our model input\n",
    "img = np.reshape(img, 28*28)\n",
    "\n",
    "#predicting the class\n",
    "print('\\nInput recognized as ' + str(final_model.predict([img])[0])+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**: The model might perform poorly due to overfitting, differences in feature distribution between training and new data, or because logistic regression's linear decision boundaries might not capture the complex patterns in handwritten digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('my_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd9fd915db2e029ec70cf1bf836846dad4f7aef8f0bedb39edb03932a58b544f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
