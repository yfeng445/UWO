{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DS3000A - DS9000A Final Exam\n",
    "\n",
    "## Student ID #: XXXXXXXXX\n",
    "\n",
    "## Grade: __ / 100 + 10 Bonus\n",
    "\n",
    "## General Comments\n",
    "\n",
    "-   This exam integrates knowledge and skills acquired in the whole term. You are allowed to use any document and source on your computer and the internet, but you are NOT allowed to share documents, post questions to online forums, or communicate in any way with people inside or outside the class. \n",
    "\n",
    "-   Having any document sharing or communication tool (e.g. Discord, Teams, Outlook, Google Drive etc.), either web-based or app-based, open on your laptop (or running in the background) is considered act of cheating and you will receive 0 pts for the exam.\n",
    "\n",
    "-   To finish the midterm in the alloted time, you will have to work efficiently. Read the entirety of each question carefully.\n",
    "\n",
    "-   You need to submit your final notebook by 1:00PM on OWL to the Test and Quizzes section, this is the same place where you downloaded the empty notebook and data. Late submission will be scored with 0 pts. To avoid technical difficulties, start your submission, at the latest, five to ten minutes before the deadline.  \n",
    "\n",
    "-   Some questions demand a **written answer** - answer these in full English sentences in markdown cells. \n",
    "\n",
    "-   For your figures, ensure that all axes are labeled in an informative way. There might be a situation where you should limit the x-axis and/or the y-axis to zoom-in for interpretation.\n",
    "\n",
    "-   Ensure that your code runs correctly by choosing \"Kernel -> Restart and Run All\" before submitting to OWL. \n",
    "\n",
    "## Additional Guidance\n",
    "\n",
    "-   If at any point you are asking yourself \"are we supposed to...\", write your assumptions clearly and proceed according to those assumptions.\n",
    "-   If you have no clue how to approach a question, skip it and move on. Revisit the skipped one(s) after you are done with the rest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preliminaries\n",
    "Feel free to add stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "seed=1220\n",
    "np.random.seed(seed)\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1 - <span style=\"color:green\">[60]</span> - Model Selection \n",
    "You are going to work on a dataset listing the soccer players participated in the 2022 FIFA World Cup. Our ultimate goal is to find the best ML model (amongst four candidates) that can best predict a player's monetary value. The dataset has the following attributes:\n",
    "- `Age`: Player age in years\n",
    "- `Nationality`: Players nationality\n",
    "- `Overall`: Player overall performance score (higher better)\n",
    "- `Potential`: Player potential score (higher better)\n",
    "- `Club`: Player home soccer club\n",
    "- `Value`: Player value *i.e*, the amount of money in euros a club should pay in order to purchase the player (higher better)\n",
    "- `Wage`: Player stipend in euros (higher better)\n",
    "- `Preferred Foot`: Player preferred foot to play\n",
    "- `International Reputation`: Player international fame (higher better)\n",
    "- `Week Foot`: Performance score of player weak foot (higher better)\n",
    "- `Skill Moves`: Player move skill score (higher better)\n",
    "- `Body Type`: Player body type\n",
    "- `Position`: Position player holds on the pitch\n",
    "- `Height`: Player height in centimeters\n",
    "- `Weight`: Player weight in kilograms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.1 - <span style=\"color:red\">[0.5]</span> - Load `dataset_1.csv` as a pandas dataframe, name it `data`, and display its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.2 - <span style=\"color:red\">[1]</span> - Code to answer the following questions:\n",
    "-   Does the data contain any missing value(s)? How do you take care of them? <span style=\"color:red\">[0.5]</span>\n",
    "-   Do you see any suspicious value(s) in the statistical summary of the data? If so, explain why suspicious and take care of them properly? <span style=\"color:red\">[0.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.3 - <span style=\"color:red\">[2]</span> - The BMI is defined as the body mass divided by the square of the body height, and is expressed in units of $kg/m^2$. With this knowledge, see if you can do some meaningful feature extraction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.4 - <span style=\"color:red\">[4]</span> - Use `sns.jointplot` to investigate the following relationships and apply proper transformations where needed:\n",
    "- Value vs. Wage\n",
    "- Value vs. Overall\n",
    "- Wage vs. Overall\n",
    "- Value vs. Potential\n",
    "- Wage vs. Potential\n",
    "\n",
    "Note: Where transformation is needed, use `sns.jointplot` twice (*i.e.*, before and after transformation).\n",
    "\n",
    "Hint: Where transformation is needed, replace the original values of the attribute in the dataset with their transformed version.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.5 - <span style=\"color:red\">[2]</span> - Output a table reporting in descending format the correlations between the numerical features and target.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.6 - <span style=\"color:red\">[6]</span> - Code the following:\n",
    "-   use pandas `get_dummies` to take care of the categorical variables, if any, <span style=\"color:red\">[2]</span>\n",
    "-   at this point, before proceeding to the next step, store the dataframe with a unique name because you will need it again in **Question 1.14 and 1.15**. <span style=\"color:red\">[1]</span>\n",
    "-   use `train_test_split` with `random_state=seed` to put aside 20% of the data for testing purpose, <span style=\"color:red\">[1]</span>\n",
    "-   define an RMSE scorer function. <span style=\"color:red\">[2]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.7 - <span style=\"color:red\">[4]</span> - Do the following:\n",
    "-   instantiate an sklearn's linear regression with the default arguments and name it `model1`, <span style=\"color:red\">[0.5]</span>\n",
    "-   run shuffled 5-split Kfold cross-validation on `model1` and report the cross-validated RMSE of each split as well as their mean and standard deviation <span style=\"color:red\">[1]</span>\n",
    "-   fit the model, <span style=\"color:red\">[0.5]</span>\n",
    "-   report prediction RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   report generalization RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   get the fitted coefficients from `model1` and use `sns.barplot` to see in descending order the 5 features that the model deems as the most important ones. (Take the absolute values of the coefficients because we just want to see the most correlated ones and do not care whether they are positively correlated or negatively). <span style=\"color:red\">[1]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.8 - <span style=\"color:red\">[5]</span> - Do the following:\n",
    "-   Bundle the `StandardScaler` with the sklearn's cross-validated ridge linear regression into a `Pipeline` and name it `model2` (for the regressor use the default arguments except `alpha = [1e-10, 1e-5, 1]` and `store_cv_values=True`), <span style=\"color:red\">[1]</span>\n",
    "-   run shuffled 5-split Kfold cross-validation on `model2` and report the cross-validated RMSE of each split as well as their mean and standard deviation, <span style=\"color:red\">[1]</span>\n",
    "-   fit the model, <span style=\"color:red\">[0.5]</span>\n",
    "-   report prediction RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   report generalization RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   which entry in the `alpha` list did the model select for training? <span style=\"color:red\">[0.5]</span>\n",
    "-   get the fitted coefficients from `model2` and use `sns.barplot` to see in descending order the 5 features that the model deems as the most important ones. (Take the absolute values of the coefficients because we just want to see the most correlated ones and do not care whether they are positively correlated or negatively). <span style=\"color:red\">[1]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.9 - <span style=\"color:red\">[4]</span> - Do the following:\n",
    "-   instantiate an sklearn's random forest regressor with the default arguments except `n_jobs=-1,` and `random_state=seed` and name it `model3`, <span style=\"color:red\">[0.5]</span>\n",
    "-   run shuffled 5-split Kfold cross-validation on `model3` and report the cross-validated RMSE of each split as well as their mean and standard deviation, <span style=\"color:red\">[1]</span>\n",
    "-   fit the model, <span style=\"color:red\">[0.5]</span>\n",
    "-   report prediction RMSE score,  <span style=\"color:red\">[0.5]</span>\n",
    "-   report generalization RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   how many trees this forest has? <span style=\"color:red\">[0.5]</span>\n",
    "-   use `barplot` to generate a variable (or feature) importance diagram from this model (limit the plot to the top 5 features). <span style=\"color:red\">[0.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.10 - <span style=\"color:red\">[2]</span> - Use the cross-validated grid search function to find the best possible values for `n_estimators` and `max_features` for the random forest. Here are the degrees of freedom to use: For `n_estimators` try `[50, 100, 150]`, and for `max_features` try every possible method.\n",
    "\n",
    "Note: Only use 50% of total data (randomly sampled using the provided random seed) to fit the grid search function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.11 - <span style=\"color:red\">[4]</span> - Do the following:\n",
    "-   Take the random forest again but this time use the best values found in the previous step (again with `n_jobs=-1,` and `random_state=seed`), and name it `model4`, <span style=\"color:red\">[1]</span>\n",
    "-   run shuffled 5-split Kfold cross-validation on `model4` and report the cross-validated RMSE of each split as well as their mean and standard deviation, <span style=\"color:red\">[1]</span>\n",
    "-   fit the model, <span style=\"color:red\">[0.5]</span>\n",
    "-   report prediction RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   report generalization RMSE score, <span style=\"color:red\">[0.5]</span>\n",
    "-   use `barplot` to generate a variable (or feature) importance diagram from this model (limit the plot to the top 5 features). <span style=\"color:red\">[0.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.12 - <span style=\"color:red\">[1]</span> - Based on your results, what features do you think are the most important ones? Which model do you trust for this purpose and why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.13 - <span style=\"color:red\">[1.5]</span> - If you are asked to choose one final model for production, which one would you select? Explain why? Note: To answer this, take computational complexity into account alongside other criteria."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.14 - <span style=\"color:red\">[10]</span> - Take the dataframe that you set aside in **Question 1.6** for this question. With `International Reputation` as label attempt to do nonlinear dimension reduction using 3-component t-SNE with `learning_rate='auto'`, `init='random`, `perplexity=50`, `random_state=seed`, and `n_jobs=-1`. You will probably witness better separations with higher values of `n_iter`, however, for the sake of computation time do not go beyond 1500 . There is no deterministic outcome to expect from this question. As long as your implementation is correct, you should get the full mark. Treat this as an **unsupervised** task. Do the following:\n",
    "-   instantiate a t-SNE model with proper arguments, <span style=\"color:red\">[2]</span>\n",
    "-   fit the model properly, <span style=\"color:red\">[2]</span>\n",
    "-   3D scatter plot the components that you get after dimension reduction and name the axes properly, <span style=\"color:red\">[3]</span>\n",
    "-   use the label to color code the data points in your 3D plot. <span style=\"color:red\">[2]</span>\n",
    "-   why t-SNE uses t-distribution and not Gaussian? <span style=\"color:red\">[1]</span>\n",
    "\n",
    "Note: If you do not know how to plot in 3D, do 2D for partial mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.15 - <span style=\"color:red\">[5]</span> - Take the dataframe that you set aside in **Question 1.6** for this question. We want to do a classification with `'International Reputation'` as target class. This is going to be an imbalanced classification but we don't care. We are interested to see if can get a better accuracy score if we do some clustering as a preprocessing step. Do the following:\n",
    "-   what would be the classification baseline accuracy for this dataframe? <span style=\"color:red\">[1]</span>\n",
    "-   use `train_test_split` with `random_state=seed` to set aside 20% of the data as test set, <span style=\"color:red\">[0.5]</span>\n",
    "-   instantiate a sklearn's stochastic gradient descent classifier with the proper solver for logistic regression and name it `clf`. Use elasticnet regularization with `l1_ratio` of 0.7. Set `max_iter=2000`, `tol=1e-3`, `n_jobs=-1`, `random_state=seed`, <span style=\"color:red\">[2]</span>\n",
    "-   run 5-split `StratifiedKFold` cross-validation on `clf` and report the cross-validated **accuracy** of each fold as well as their mean and standard deviation, <span style=\"color:red\">[1.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1.16 - <span style=\"color:red\">[8]</span> - Do the following:\n",
    "-   bundle a 50-cluster `K-Means` (as a preprocessing step) and the `clf` into a pipeline. Set `random_state=seed` for `K-Means`, <span style=\"color:red\">[3]</span>\n",
    "-   run 5-split `StratifiedKFold` cross-validation on the pipeline and report the cross-validated **accuracy** of each fold as well as their mean and standard deviation, <span style=\"color:red\">[2]</span>\n",
    "-   do you find the added preprocessing step effective? why? <span style=\"color:red\">[1]</span>\n",
    "-   what transformations did the data undergo through this pipeline? <span style=\"color:red\">[2]</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 - <span style=\"color:green\">[40]</span> - Clustering \n",
    "For this question we use a modified dataset from UCI Machine Learning Datasets. The data contains selling features on a social media platform. Each record has information about the time the information was posted and engagements such as emotion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.1 - <span style=\"color:red\">[1]</span> - Load `dataset_2.csv` as a pandas dataframe, name it `df2`, and display its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df2 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.2 - <span style=\"color:red\">[8]</span> - Do the following:\n",
    "-   How many observations and attributes do you see in the dataset? <span style=\"color:red\">[1]</span>\n",
    "-   Check for missing values and drop the columns that contain missing values. <span style=\"color:red\">[1]</span>\n",
    "-   Create a label encoder using `LabelEncoder` from sklearn and convert the categorical variable into numerics. <span style=\"color:red\">[2]</span>\n",
    "-   Keep a copy of the encoded version of `df2['data_type']` under a different name (*e.g.*, `y`) - you will need it in **Question 2.6** as true label. <span style=\"color:red\">[1]</span>\n",
    "-   Explain why it is a good idea to normalize the data for K-Means clustering. <span style=\"color:red\">[1]</span>\n",
    "-   Train a `MinMaxScaler` over the full dataset but not `y`. <span style=\"color:red\">[2]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.3 - <span style=\"color:red\">[4]</span> - Now that the data is ready let's use `KMeans` with `random_state=seed` to plot k versus inertia for the model. Take k in `[2, 3, 4, 5, 6, 8]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.4 - <span style=\"color:red\">[4]</span> - Plot k versus silhouette score for the model fit in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.5 - <span style=\"color:red\">[5]</span> - According to the plots of **Question 2.3** and **Question 2.4** select 4 values for k and generate Silhouette Diagrams for them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.6 - <span style=\"color:red\">[5]</span> - Train the model (using the same seed) for the k's that you selected in the previous question and report the model accuracy per k. Hint: In order to calculate the number of correct cluster labels you can use the data that you set aside in **Question 2.2** as true label for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.7 - <span style=\"color:red\">[3]</span> - Based on the insights generated in **Question 2.3 - 2.6**, pick two values for **k**. Explain why and support your choices by the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.8 - <span style=\"color:red\">[6]</span> - Do the following:\n",
    "-   In **Question 2.2**, you used `MinMaxScaler`. This time, instead of `MinMaxScaler`, use the `StandardScaler()` to prepare the data once again. Train `KMeans` on this data with `random_state=seed` and number of clusters being equal to your first choice for **k**. <span style=\"color:red\">[3]</span>\n",
    "-   Apply a PCA transform to the data using 3 components and create a 3D scatter plot, differentiating data points by color. <span style=\"color:red\">[3]</span>\n",
    "\n",
    "Note: If you do not know how to plot in 3D, do 2D for partial mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.9 - <span style=\"color:red\">[3]</span> - Retrain the `KMeans` with number of clusters being equal to your second choice for k, and again apply a PCA transform to the data using 3 components and create a 3D scatter plot, differentiating data points by color.\n",
    "\n",
    "Note: If you do not know how to plot in 3D, do 2D for partial mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2.10 - <span style=\"color:red\">[1]</span> - After seeing the figures generated in **Question 2.8** and **2.9**, what value of **k** would be your ultimate choice? Explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 - <span style=\"color:green\">[10 Bonus]</span> - ANN\n",
    "Let's use the same dataset as **Question 1** to train an ANN to predict players values. You can use either PyTorch or TensorFlow.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3.1 - <span style=\"color:red\">[2]</span> - Load `dataset_1.csv` as a pandas dataframe, create the array of features `X` and target `y`. Use `train_test_split` with `random_state=seed,test_size=0.3` twice to get not only a training set and a test set but also a validation set. Use `StandardScaler()` to transform X's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3.2 - <span style=\"color:red\">[3]</span> - Create an ANN with 4 layers:\n",
    "-   An input layer with 500 nodes\n",
    "-   A hidden layer with 100 nodes\n",
    "-   Another hidden layer with 50 nodes\n",
    "-   A single node output layer\n",
    "\n",
    "It is up to you where and what type of activation function to use.\n",
    "\n",
    "How many parameters your ANN must optimize?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3.3 - <span style=\"color:red\">[3]</span> - Choose `mean_squared_error` for loss and train the model (with `epochs=20`) over training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3.4 - <span style=\"color:red\">[1]</span> - Report both prediction and generalization loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3.5 - <span style=\"color:red\">[1]</span> - Plot the learning curve *i.e.*, epoch vs training loss and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Warning!\n",
    "\n",
    "Upload your complete notebook to the same place on OWL where you initially downloaded it. After uploading, click the \"Submit for Grading\" button and confirm. Late submissions are not allowed, so please start the submission process 10 minutes before the deadline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
