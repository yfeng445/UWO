{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DS3000A - DS9000A Midterm Exam\n",
    "\n",
    "## Student ID #: XXXXXXXXX\n",
    "\n",
    "## Grade: __ / 100\n",
    "\n",
    "## General Comments\n",
    "\n",
    "-   This exam integrates knowledge and skills acquired in the first half of the semester. You are allowed to use any document and source on your computer and look up documents on the internet, but you are NOT allowed to share documents, post questions to online forums, or communicate in any way with people inside or outside the class, . \n",
    "\n",
    "-   Having open any document sharing or communication tool (e.g. Discord, Teams, Outlook, Google Drive etc.) either web-based or app-based on your laptop (or having them running in the background) is considered act of cheating and you will receive 0 pts for the exam.\n",
    "\n",
    "-   To finish the midterm in the alloted time, you will have to work efficiently. Read the entirety of each question carefully.\n",
    "\n",
    "-   You need to submit the midterm by 6:15PM on OWL to the Test and Quizzes section, where you downloaded the notebook and data. Late submission will be scored with 0 pts. To avoid technical difficulties, start your submission, at the latest, five to ten minutes before the deadline.  \n",
    "\n",
    "-   Some questions demand a **written answer** - answer these in a full English sentence in their allocated markdown cells. \n",
    "\n",
    "-   For your figures, ensure that all axes are labeled in an informative way. In order to interpret, there can be a situation where you should limit the x-axis and/or y-axis to zoom-in.\n",
    "\n",
    "-   Ensure that your code runs correctly by choosing \"Kernel -> Restart and Run All\" before submitting to OWL. \n",
    "\n",
    "## Additional Guidance\n",
    "\n",
    "-   If at any point you are asking yourself \"are we supposed to...\", write your assumptions clearly and proceed according to those assumptions.\n",
    "-   If you have no clue how to approach a question, skip it and move on. Revisit the skipped one(s) after you are done with other questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preliminaries\n",
    "Feel free to add stuff to Preliminaries. However, be mindful of every question's restrictions as some may exclude use of some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score, roc_curve, auc, RocCurveDisplay, roc_auc_score, accuracy_score, classification_report#, plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "seed=1110\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1 - Hardcode Linear Regression <span style=\"color:green\">[10 marks]</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.1 - <span style=\"color:red\">[0.5]</span> - Load `q1q2.csv` as pandas dataframe (name it `df1`) and show its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 ="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.2 - <span style=\"color:red\">[0.5]</span> - Use an appropriate plotting command to see the relationship between `x1` and `y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.3 - <span style=\"color:red\">[5]</span> - Hardcode OLS linear regression. You need at least two functions:\n",
    "-   A loss function (name it `Loss`): Takes `(b, X, y)` as input arguments, calculates OLS cost function, and `return`s the calculated values. Note that this function must `return` only one variable which is a 1D array consisting of the calculated values. <span style=\"color:red\">[2]</span>\n",
    "-   A fitting function (name it `Fit`): Takes `(X, y, lossfcn=Loss)` as input arguments and returns two variables i.e. estimated betas and R-squared. This function must use `scipy.optimize.minimize` to minimize the `Loss` function. <span style=\"color:red\">[3]</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(b, X, y):\n",
    "    \n",
    "    return c # must only return the calculated values of the cost function (here called `c`)\n",
    "\n",
    "\n",
    "def Fit(X, y, lossfcn=Loss):\n",
    "    \n",
    "    return (estimated_betas, R2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.4 - <span style=\"color:red\">[1]</span> - Do these:\n",
    "-   Construct a target `y` using `y1`, and a feature matrix `X_a` using `x1` without any feature transformation.<span style=\"color:red\">[0.25]</span>\n",
    "-   Use `X_a` and `y` and call `Fit` to fit your model. <span style=\"color:red\">[0.25]</span>\n",
    "-   What is training R-squared of this model? <span style=\"color:red\">[0.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.5 - <span style=\"color:red\">[2]</span> - Do these:\n",
    "-   Construct a new feature matrix `X_b` using `x1` but this time also include a transformation of `x1` that you deem to best describe the relationship between `x1` and `y1`. Take a look at your plot of Q 1.2 and try to identify the relationship. <span style=\"color:red\">[1]</span>\n",
    "-   Use `X_b` and `y` and call `Fit` to fit your model <span style=\"color:red\">[0.5]</span>\n",
    "-   What is training R-squared of this model? <span style=\"color:red\">[0.5]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.6 - <span style=\"color:red\">[1]</span> - Use the given `xnew` below to construct two test design matrices i.e., one without any transformation (name it `X_new_a`) and one with the transformation identified in Q 1.5 (name it `X_new_b`). Make predictions for both. Plot these predictions and the original data points all together in one plot window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = np.linspace(df1.x1.min(), df1.x1.max(), 100)\n",
    "\n",
    "X_new_a\n",
    "X_new_b\n",
    "\n",
    "y_pred_a\n",
    "y_pred_b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2 - Hardcode Maximum Likelihood Regression <span style=\"color:green\">[20 marks]</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.1 - <span style=\"color:red\">[15]</span> - Code an OLS regression log likelihood using this probability density function:\n",
    "\n",
    "$f_Y(y|X=x)=\\dfrac{\\pi}{3\\sigma_{\\epsilon}\\sqrt{2\\pi}}e^{-\\dfrac{1}{2}\\dfrac{(y-\\mu_{Y})^2}{\\sigma_{\\epsilon}^2\\sqrt{\\pi}}}$\n",
    "\n",
    "You can assume $\\sigma_{\\epsilon}$ to be the standard deviation of the noise in the data (hint: for which you can assume an arbitrary value but must be a valid one). You need to calculate the log likelihood of the PDF (_i.e._, $l(\\mu_{Y},\\sigma_{\\epsilon}^2;y_1,...,y_n$)), and then choose the form of $\\mu_{Y}$ using some assumptions that you make. You can start to code once you know the final form of the $l$ equation. You need to code at least two functions:\n",
    "- one which takes in `(beta, X, y)`, calculates and `return`s $-l$. <span style=\"color:red\">[12]</span>\n",
    "- another one which takes in `(X, y, theFunctionFromThePreviousStep)` and makes use of `scipy.optimize.minimize` to minimize the previous function. This function `return`s the betas which maximize $l$. <span style=\"color:red\">[3]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.2 - <span style=\"color:red\">[0.5]</span> - Load `q1q2.csv` as pandas dataframe (name it `df2`) and show its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.3 - <span style=\"color:red\">[3]</span> - Take `x2` as feature and `y2` as target. Fit the model. Use the given `x_new` (below) to make new predictions. Plot the original data points and the new predictions in the same plot window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.linspace(x_train.min(), x_train.max(), 100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.4 - <span style=\"color:red\">[1.5]</span> - Calculate training R-squared of your Maximum Likelihood Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3: An End-to-End DS Project <span style=\"color:green\">[45 marks]</span>\n",
    "\n",
    "You are going to work on a newly published dataset which lists soccer players participating in the FIFA World Cup 2022 - Qatar. Our ultimate goal is to train a linear regression model to predict monetary values of the players."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.1 - <span style=\"color:red\">[0.5]</span> - Load the dataset `q3.csv` as pandas dataframe and take a look at its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.2 - <span style=\"color:red\">[1]</span> - What is the `Nationality`, `Wage`, `Value`, `Skill Moves`, `Overall` of `Cristiano Ronaldo` the player? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.3 - <span style=\"color:red\">[4]</span> - The feature `Overall` indicates player's overall performance score, which normally ranges from 0 to 100. However, it seems the participating players in this FIFA World Cup all have `Overall` $>40$. Plot the smoothed distribution of `Overall`. Your plot must also include three vertical lines: one for mean, one for median, and one for 99.94th percentile of the distribution. Your plot must have a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.4 - <span style=\"color:red\">[2]</span> - What is `Name`, `Nationality`, `Wage`, `Value`, `Skill Moves`, and `Overall` of the top 0.06% players of the `Overall` distribution?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.5 - <span style=\"color:red\">[0.5]</span> - What features are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.6 - <span style=\"color:red\">[1]</span> - Some features such as `ID` and `Kit Number` are obviously irrelevant for player `Value` prediction and one would drop them. However, for the sake of time let's drop some more _i.e_, the following columns:\n",
    "\n",
    "`ID`, `Name`, `Nationality`, `Photo`, `Flag`, `Club`, `Club Logo`, `Real Face`, `Joined`, `Loaned From`, `Contract Valid Until`, `Kit Number`, `Work Rate`, `Special`, `Release Clause`, `Best Overall Rating`\n",
    "\n",
    "Show the first 5 rows after the drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.7 - <span style=\"color:red\">[2]</span> - Now let's do some data cleaning on `Height` and `Weight`:\n",
    "\n",
    "`Height` and `Weight` are categorical. But we need numbers. First, remove any possible white spaces from their entries using `data['column_name'] = data['column_name'].str.replace(' ', '_')`. Second, eliminate \"cm\" and \"kg\" from their entries. Third, convert their types to numerical.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.8 - <span style=\"color:red\">[4]</span> - Now let's do some data cleaning on `Value` and `Wage`:\n",
    "\n",
    "-   Remove white spaces\n",
    "-   Drop the \"â‚¬\" symbol from their entries\n",
    "-   You should have realized that some contain a \"K\" and some contain an \"M\". We need to first store their corresponding indices before removing \"K\" and \"M\". Because after removing and conversion to numerical, you then want to multiply \"K\" entries by 1e+3 and \"M\" entries by 1e+6.\n",
    "\n",
    "There are many ways to achieve these steps. And, it does not matter how you do as long as outputs are correct. For example, for the multiplication part one can do:\n",
    "`data.loc[K_indices, ColumnName] = data[ColumnName].apply(lambda x: x*1e+3)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.9 - <span style=\"color:red\">[2]</span> - Now use the pandas `describe()` to get a statistical summary of the data. Do you spot any suspicious \"min\" values? If yes, explain why they are suspicious and replace them; also explain your choice of value for the replacement of those.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.10 - <span style=\"color:red\">[1]</span> - Drop any NA values from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.11 - <span style=\"color:red\">[3]</span> - Let's look at statistical significance of the labels within each categorical feature. Here we take 4% as the threshold for statistical significance. Use your judgment for regrouping of the labels where needed. Below is how I would do it for `Position`. You do the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'Position'\n",
    "name = 'Back';    data[cat].replace({'GK':name, 'CB':name, 'RCB':name, 'LCB':name, 'LB':name, 'RB':name, 'RWB':name, 'LWB':name, 'LW':name, 'RW':name}, inplace=True)\n",
    "name = 'Middle';  data[cat].replace({'RM':name, 'LM':name, 'RCM':name, 'LCM':name, 'RDM':name, 'LDM':name, 'CM':name, 'LAM':name, 'RAM':name, 'CDM':name, 'CAM':name}, inplace=True)\n",
    "name = 'Forward'; data[cat].replace({'ST':name, 'LF':name, 'RF':name, 'CF':name, 'RS':name, 'LS':name}, inplace=True)\n",
    "name = 'Reserve'; data[cat].replace({'SUB':name, 'RES':name}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.12 - <span style=\"color:red\">[1]</span> - Now perform one hot encoding to prepare our categorical values for linear regression. Store the encoded dataset under the name `df3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.13 - <span style=\"color:red\">[2]</span> - Use `seaborn.jointplot` to investigate the relationship between `Overall` vs `Value` as well as `Wage` vs `Value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.14 - <span style=\"color:red\">[4]</span> - Where applicable, apply proper transformation on either `Overall`, `Wage`, or `Value` to make them better fit the assumptions of linear regression. Joinplot the transformed versions before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.15 - <span style=\"color:red\">[2]</span> - Add the the transformed variables to the dataframe `df3` as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.16 - <span style=\"color:red\">[2]</span> - Use heatmap to study the pairwise correlations of all the variables in `df3`. In one or two sentences tell where you see two or three strong correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.17 - <span style=\"color:red\">[8]</span> - Let's train a model to predict player value using all features in `df3` except some (you tell):\n",
    "- Use RMSE as your scorer <span style=\"color:red\">[1]</span>\n",
    "- Split `df3` to train and test with `test_size=0.2, random_state=seed` <span style=\"color:red\">[2]</span>\n",
    "- Pick `LinearRegression()` from sklearn as your model <span style=\"color:red\">[1]</span>\n",
    "- Do 5-split Kfold cross-validation with shuffling and report the cross-validated RMSE of each split as well as their mean and standard deviation <span style=\"color:red\">[2]</span>\n",
    "- Report both prediction and generalization RMSE of your model <span style=\"color:red\">[2]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.18 - <span style=\"color:red\">[1]</span> - What value your model predict for player L. Messi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.19 - <span style=\"color:red\">[4]</span> - Let's calculate a confidence interval (based on 95% confidence level) for **mean** `Value` by bootstrapping. For this purpose, code a function that takes as input arguments (`model`, `Xtrain`, `ytrain`, `Xtest`, `numboot=100`), and in each iteration, it bootstrap samples from the training set to fit the input model and uses the test set to make predictions. The function must return only one object that is the dataframe (or array) of the recorded values of the bootstrap statistic. \n",
    "\n",
    "Depending on your approach to code the function, you may or may not need a command to combine and convert arrays to dataframe; if you do, here is one way to do it:\n",
    "\n",
    "`data = pd.DataFrame.from_records(np.c_[A, B])`\n",
    "\n",
    "Code the function, call it, and report the CI. (For `numboot`, use the function's default value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 4: Classification <span style=\"color:green\">[25 marks]</span>\n",
    "\n",
    "We want to classify players based on preferred foot (_i.e._, left or right)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.1 - <span style=\"color:red\">[0.5]</span> - Load `q4.csv` as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.2 - <span style=\"color:red\">[2.5]</span> - Are the classes balanced or imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.3 - <span style=\"color:red\">[3]</span> - What would be the baseline accuracy of such classifier and what does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.4 - <span style=\"color:red\">[9]</span> - Let's train a classifier:\n",
    "-   Split `df4` to train and test with `test_size=0.2, random_state=seed` <span style=\"color:red\">[2]</span>\n",
    "-   Use sklearn's `LogisticRegression()` with Ridge as penalty and regularization strength of 50 and `max_iter=1000`. <span style=\"color:red\">[2]</span>\n",
    "-   Do you need any preprocessing? If so, bundle them into a pipeline. <span style=\"color:red\">[3]</span>\n",
    "-   Plot ROC and report AUC? Interpret them in one or two sentences. <span style=\"color:red\">[2]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.5 - <span style=\"color:red\">[3]</span> - Report the coefficients that your model calculate. Report and interpret both the most positively and negatively correlated predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.6 - <span style=\"color:red\">[3]</span> - What is the accuracy of the model (over test set)? What do you conclude now (in general) in terms of usefulness of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.7 - <span style=\"color:red\">[4]</span> - The stakeholder of the project requires you to tune the probability threshold of your model in a way that your model's accuracy is equal to its specificity. What threshold would you choose?\n",
    "\n",
    "Hint: One way to find the value is to plot `threshold = np.linspace(0,1,200, endpoint=False)` against accuracy and specificity in the same plot window and make interpretation from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Warning!\n",
    "\n",
    "Upload your complete notebook to the same place on OWL where you initially downloaded it. After uploading, click the \"Submit for Grading\" button and confirm. Late submissions are not allowed, so please start the submission process 10 minutes before the deadline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33450fd3005a3f920860570602bb6b9ad3febc9347ad497c595fea1c977e6b53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
